{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewers asked to compare our method to PCA, ICA, SVD, and VAEs with sparsity priors.\n",
    "I can start with PCA, ICA, and SVD.\n",
    "I guess what I should do is to run these on the data and compare the redundancy, recovery, and coverage for the simulation,\n",
    "and the GO annotation for the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go 2 steps back\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from src.functions.sae_analysis_sim3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Running on a subset with 30000 samples.\n"
     ]
    }
   ],
   "source": [
    "complexity = 'high'\n",
    "n_samples = 100000\n",
    "data_dir = '/home/vschuste/data/simulation/'\n",
    "\n",
    "for seed in range(10):\n",
    "    temp_y = torch.load(data_dir+'large_{}-complexity_rs{}_y.pt'.format(complexity, seed), weights_only=False)\n",
    "    temp_x0 = torch.load(data_dir+'large_{}-complexity_rs{}_x0.pt'.format(complexity, seed), weights_only=False)\n",
    "    temp_x1 = torch.load(data_dir+'large_{}-complexity_rs{}_x1.pt'.format(complexity, seed), weights_only=False)\n",
    "    temp_x2 = torch.load(data_dir+'large_{}-complexity_rs{}_x2.pt'.format(complexity, seed), weights_only=False)\n",
    "    temp_ct = torch.load(data_dir+'large_{}-complexity_rs{}_ct.pt'.format(complexity, seed), weights_only=False)\n",
    "    temp_cov = torch.load(data_dir+'large_{}-complexity_rs{}_co.pt'.format(complexity, seed), weights_only=False)\n",
    "    if seed == 0:\n",
    "        rna_counts = temp_y\n",
    "        x0 = temp_x0\n",
    "        x1 = temp_x1\n",
    "        x2 = temp_x2\n",
    "        ct = temp_ct\n",
    "        co = temp_cov\n",
    "    else:\n",
    "        rna_counts = torch.cat((rna_counts, temp_y), dim=0)\n",
    "        x0 = torch.cat((x0, temp_x0), dim=0)\n",
    "        x1 = torch.cat((x1, temp_x1), dim=0)\n",
    "        x2 = torch.cat((x2, temp_x2), dim=0)\n",
    "        ct = torch.cat((ct, temp_ct), dim=0)\n",
    "        co = torch.cat((co, temp_cov), dim=0)\n",
    "# limit to the training data\n",
    "n_samples_train = int(n_samples*0.9)\n",
    "rna_counts = rna_counts[:n_samples_train]\n",
    "x0 = x0[:n_samples_train]\n",
    "x1 = x1[:n_samples_train]\n",
    "x2 = x2[:n_samples_train]\n",
    "ct = ct[:n_samples_train]\n",
    "co = co[:n_samples_train]\n",
    "# also make this faster by taking every 10th sample\n",
    "rna_counts = rna_counts[::3]\n",
    "x0 = x0[::3]\n",
    "x1 = x1[::3]\n",
    "x2 = x2[::3]\n",
    "ct = ct[::3]\n",
    "co = co[::3]\n",
    "\n",
    "print(\"Data loaded.\")\n",
    "print(f\"Running on a subset with {rna_counts.shape[0]} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr(a,b):\n",
    "    #cov = torch.mean((a - a.mean(dim=0).unsqueeze(0)).unsqueeze(1) * (b - b.mean(dim=0).unsqueeze(0)).unsqueeze(-1), dim=0)\n",
    "    cov = torch.mean((a - a.mean(dim=0)) * (b - b.mean()).unsqueeze(-1), dim=0)\n",
    "    #std_a = a.std(dim=0)\n",
    "    std_a = a.std(dim=0)\n",
    "    #std_b = b.std(dim=0)\n",
    "    std_b = b.std()\n",
    "    return cov / (std_a * std_b)\n",
    "\n",
    "def get_correlations_with_data(activations, unique_activs, comparison_data, device='cpu'):\n",
    "    correlations_p = torch.zeros((len(unique_activs), comparison_data.shape[1]))\n",
    "    \n",
    "    # Move data to GPU once, not in every loop iteration\n",
    "    with torch.no_grad():        \n",
    "        # Process in smaller batches to avoid memory issues\n",
    "        batch_size = 5000  # Adjust based on your GPU memory\n",
    "        for start_idx in range(0, comparison_data.shape[1], batch_size):\n",
    "            end_idx = min(start_idx + batch_size, comparison_data.shape[1])\n",
    "            \n",
    "            # Calculate correlations for the batch\n",
    "            for j in tqdm.tqdm(range(0, comparison_data.shape[1])):\n",
    "                correlations_p[start_idx:end_idx, j] = pearsonr(activations[:,start_idx:end_idx].to(device), comparison_data[:, j].to(device)).cpu()\n",
    "            \n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return correlations_p.numpy()\n",
    "\n",
    "def get_number_of_redundant_features(activations, threshold=0.95, device='cpu'):\n",
    "    # compute correlations between all active features\n",
    "    redundant_set = set()\n",
    "    # Move data to GPU once, not in every loop iteration\n",
    "    with torch.no_grad():        \n",
    "        # Process in smaller batches to avoid memory issues\n",
    "        batch_size = 5000  # Adjust based on your GPU memory\n",
    "        for j in tqdm.tqdm(range(0, activations.shape[1])):\n",
    "            corr_temp = torch.zeros(activations.shape[1])\n",
    "            for start_idx in range(0, activations.shape[1], batch_size):\n",
    "                end_idx = min(start_idx + batch_size, activations.shape[1])\n",
    "                corr_temp[start_idx:end_idx] = pearsonr(activations[:,start_idx:end_idx].to(device), activations[:, j].to(device)).cpu()\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        redundant_set.update([j for j in np.where(corr_temp.numpy() > threshold)[0]])\n",
    "    n_redundant = len(redundant_set)\n",
    "    return n_redundant\n",
    "\n",
    "def analyze_dimreduction_methods(latent, comparison_data, redundant=False, device='cpu'):\n",
    "    if redundant:\n",
    "        n_redundant = get_number_of_redundant_features(latent, threshold=0.95, device=device)\n",
    "    else:\n",
    "        n_redundant = None\n",
    "    corrs = get_correlations_with_data(latent, np.arange(latent.shape[1]), comparison_data, device=device)\n",
    "    n_per_attribute = get_n_features_per_attribute(corrs)\n",
    "    highest_corrs = get_highest_corr_per_attribute(corrs)\n",
    "    return n_redundant, n_per_attribute, highest_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA...\n"
     ]
    }
   ],
   "source": [
    "# run PCA on the data\n",
    "print(\"Running PCA...\")\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=rna_counts.shape[1])\n",
    "pca.fit(rna_counts)\n",
    "embed = torch.tensor(pca.transform(rna_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.55it/s]\n"
     ]
    }
   ],
   "source": [
    "def torch_corrcoef(x, epsilon=1e-6):\n",
    "    # calculate the covariance\n",
    "    mean_x = torch.mean(x, dim=1)\n",
    "    xm = x - mean_x.unsqueeze(1)\n",
    "    cov = xm @ xm.T# / (x.shape[1] - 1)\n",
    "    # calculate the standard deviation\n",
    "    std_x = torch.sqrt(torch.diag(cov)) + epsilon\n",
    "    # calculate the correlation\n",
    "    correlation = cov / (std_x.unsqueeze(0) * std_x.unsqueeze(1))\n",
    "    return correlation\n",
    "\n",
    "def get_number_of_redundant_features(activations, threshold=0.95, device='cpu'):\n",
    "    # compute correlations between all active features\n",
    "    redundant_set = set()\n",
    "    # Move data to GPU once, not in every loop iteration\n",
    "    with torch.no_grad():        \n",
    "        # Process in smaller batches to avoid memory issues\n",
    "        batch_size = 5000  # Adjust based on your GPU memory\n",
    "        for j in tqdm.tqdm(range(0, activations.shape[1])):\n",
    "            corr_temp = torch.zeros(activations.shape[1])\n",
    "            for start_idx in range(0, activations.shape[1], batch_size):\n",
    "                end_idx = min(start_idx + batch_size, activations.shape[1])\n",
    "                corr_temp[start_idx:end_idx] = pearsonr(activations[:,start_idx:end_idx].to(device), activations[:, j].to(device)).cpu()\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        redundant_set.update([j for j in np.where(corr_temp.numpy() > threshold)[0]])\n",
    "    n_redundant = len(redundant_set)\n",
    "    return n_redundant\n",
    "\n",
    "n_redundant = get_number_of_redundant_features(x0, threshold=0.95, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running y\n",
      "Running x0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 46.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running x1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:00<00:00, 51.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning x1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m x1_metrics \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_dimreduction_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredundant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     12\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[42], line 37\u001b[0m, in \u001b[0;36manalyze_dimreduction_methods\u001b[0;34m(latent, comparison_data, redundant, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     n_redundant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m corrs \u001b[38;5;241m=\u001b[39m \u001b[43mget_correlations_with_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomparison_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m n_per_attribute \u001b[38;5;241m=\u001b[39m get_n_features_per_attribute(corrs)\n\u001b[1;32m     39\u001b[0m highest_corrs \u001b[38;5;241m=\u001b[39m get_highest_corr_per_attribute(corrs)\n",
      "Cell \u001b[0;32mIn[42], line 22\u001b[0m, in \u001b[0;36mget_correlations_with_data\u001b[0;34m(activations, unique_activs, comparison_data, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate correlations for the batch\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, comparison_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])):\n\u001b[0;32m---> 22\u001b[0m     correlations_p[start_idx:end_idx, j] \u001b[38;5;241m=\u001b[39m pearsonr(activations[:,start_idx:end_idx]\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mcomparison_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     24\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Running y\")\n",
    "y_metrics = analyze_dimreduction_methods(embed, rna_counts, redundant=False, device=device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Running x0\")\n",
    "x0_metrics = analyze_dimreduction_methods(embed, x0, redundant=False, device=device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Running x1\")\n",
    "x1_metrics = analyze_dimreduction_methods(embed, x1, redundant=False, device=device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Running x2\")\n",
    "x2_metrics = analyze_dimreduction_methods(embed, x2, redundant=False, device=device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Running ct\")\n",
    "ct_metrics = analyze_dimreduction_methods(embed, ct.float().unsqueeze(1), redundant=False, device=device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Running co\")\n",
    "co_metrics = analyze_dimreduction_methods(embed, co.float().unsqueeze(1), redundant=False, device=device)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_metrics[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metrics\n",
    "df_y = pd.DataFrame({'n_redundant': y_metrics[0], 'n_per_attribute (mean)': y_metrics[1].mean(), 'n_per_attribute (max)': y_metrics[1].max(), 'highest_corrs (mean)': y_metrics[2].mean(), 'highest_corrs (max)': y_metrics[2].max(), 'variable': 'y'})\n",
    "df_x0 = pd.DataFrame({'n_redundant': y_metrics[0], 'n_per_attribute (mean)': x0_metrics[1].mean(), 'n_per_attribute (max)': x0_metrics[1].max(), 'highest_corrs (mean)': x0_metrics[2].mean(), 'highest_corrs (max)': x0_metrics[2].max(), 'variable': 'x0'})\n",
    "df_x1 = pd.DataFrame({'n_redundant': y_metrics[0], 'n_per_attribute (mean)': x1_metrics[1].mean(), 'n_per_attribute (max)': x1_metrics[1].max(), 'highest_corrs (mean)': x1_metrics[2].mean(), 'highest_corrs (max)': x1_metrics[2].max(), 'variable': 'x1'})\n",
    "df_x2 = pd.DataFrame({'n_redundant': y_metrics[0], 'n_per_attribute (mean)': x2_metrics[1].mean(), 'n_per_attribute (max)': x2_metrics[1].max(), 'highest_corrs (mean)': x2_metrics[2].mean(), 'highest_corrs (max)': x2_metrics[2].max(), 'variable': 'x2'})\n",
    "df_ct = pd.DataFrame({'n_redundant': y_metrics[0], 'n_per_attribute (mean)': ct_metrics[1][0], 'n_per_attribute (max)': ct_metrics[1][0], 'highest_corrs (mean)': ct_metrics[2][0], 'highest_corrs (max)': ct_metrics[2][0], 'variable': 'ct'})\n",
    "df_co = pd.DataFrame({'n_redundant': y_metrics[0], 'n_per_attribute (mean)': co_metrics[1][0], 'n_per_attribute (max)': co_metrics[1][0], 'highest_corrs (mean)': co_metrics[2][0], 'highest_corrs (max)': co_metrics[2][0], 'variable': 'co'})\n",
    "df_pca = pd.concat([df_y, df_x0, df_x1, df_x2, df_ct, df_co], axis=0)\n",
    "df_pca.to_csv('03_results/reports/files/sim2L_pca_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ICA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vschuste/miniconda3/envs/sc_mechinterp/lib/python3.9/site-packages/sklearn/decomposition/_fastica.py:494: FutureWarning: Starting in v1.3, whiten='unit-variance' will be used by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# perform ICA\n",
    "print(\"Running ICA...\")\n",
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=rna_counts.shape[1], random_state=0)\n",
    "ica.fit(rna_counts)\n",
    "#embed = torch.tensor(ica.transform(rna_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.tensor(ica.transform(rna_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVD...\n"
     ]
    }
   ],
   "source": [
    "# perform SVD\n",
    "print(\"Running SVD...\")\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=rna_counts.shape[1])\n",
    "svd.fit(rna_counts)\n",
    "embed = torch.tensor(svd.transform(rna_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sparse_vae import *\n",
    "\n",
    "# Create a VAE with Laplace prior\n",
    "input_dim = rna_counts.shape[1]\n",
    "scaling_factor = 1.0\n",
    "latent_dim = int(scaling_factor * 150)\n",
    "svae = PriorVAE(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=int(abs(input_dim - latent_dim) / 2),\n",
    "    latent_dim=latent_dim,\n",
    "    prior_type='laplace'  # Options: 'gaussian', 'laplace', 'cauchy'\n",
    ")\n",
    "# write a dataloader for the rna_counts data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Assuming rna_counts is a PyTorch tensor of shape (n_samples, n_features)\n",
    "batch_size = 128\n",
    "data_loader = DataLoader(\n",
    "    TensorDataset(rna_counts),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "svae.to(device)\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.Adam(svae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<05:59,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 969.3763, Recon: 203.6758, KL: 7657.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:07<05:41,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 945.6853, Recon: 156.3649, KL: 7893.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:10<05:34,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Loss: 941.7326, Recon: 152.6639, KL: 7890.6872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:13<05:28,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 939.3570, Recon: 151.2392, KL: 7881.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:17<05:24,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 938.2517, Recon: 149.4475, KL: 7888.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:20<05:20,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Loss: 937.1631, Recon: 147.2787, KL: 7898.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:24<05:16,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Loss: 931.3068, Recon: 145.0820, KL: 7862.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:27<05:13,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Loss: 936.6593, Recon: 147.6109, KL: 7890.4841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:30<05:10,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Loss: 933.7231, Recon: 143.8287, KL: 7898.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:34<05:07,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 931.7667, Recon: 143.7105, KL: 7880.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:37<05:04,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Loss: 931.7539, Recon: 143.4995, KL: 7882.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:41<05:01,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Loss: 932.3440, Recon: 143.2713, KL: 7890.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:44<04:58,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Loss: 929.1254, Recon: 142.6935, KL: 7864.3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:47<04:55,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Loss: 931.4654, Recon: 143.5247, KL: 7879.4076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:51<04:52,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Loss: 929.9656, Recon: 142.8737, KL: 7870.9194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:54<04:49,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Loss: 930.8343, Recon: 142.6945, KL: 7881.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:58<04:46,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Loss: 931.1044, Recon: 142.4506, KL: 7886.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:01<04:43,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Loss: 933.0772, Recon: 143.0218, KL: 7900.5540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:05<04:40,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Loss: 929.2501, Recon: 142.2766, KL: 7869.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:08<04:37,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 930.9763, Recon: 143.0353, KL: 7879.4106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:12<04:34,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Loss: 930.6695, Recon: 143.2789, KL: 7873.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:15<04:31,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Loss: 930.6161, Recon: 144.0991, KL: 7865.1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:19<04:28,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Loss: 929.1857, Recon: 142.2489, KL: 7869.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:22<04:25,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Loss: 932.6307, Recon: 142.5204, KL: 7901.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:26<04:22,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Loss: 930.6281, Recon: 142.0378, KL: 7885.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:29<04:19,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Loss: 929.5031, Recon: 142.4815, KL: 7870.2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:33<04:15,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Loss: 930.6729, Recon: 142.1355, KL: 7885.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:34<04:15,  3.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m svae \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get the latent representation in batches\u001b[39;00m\n\u001b[1;32m      4\u001b[0m svae\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/projects/interpreting_omics_models/src/models/sparse_vae.py:186\u001b[0m, in \u001b[0;36mtrain_vae\u001b[0;34m(model, optimizer, data_loader, epochs, device)\u001b[0m\n\u001b[1;32m    183\u001b[0m recon_batch, mu, logvar, _ \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m loss, recon_loss, kl_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m    189\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/projects/interpreting_omics_models/src/models/sparse_vae.py:149\u001b[0m, in \u001b[0;36mPriorVAE.loss_function\u001b[0;34m(self, recon_x, x, mu, logvar)\u001b[0m\n\u001b[1;32m    146\u001b[0m kl_div \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_divergence(mu, logvar)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Detect NaNs early\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(recon_loss) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(kl_div):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in loss calculation!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(recon_loss):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "svae = train_vae(svae, optimizer, data_loader, epochs=100, device=device)\n",
    "# Get the latent representation in batches\n",
    "svae.eval()\n",
    "batch_size = 5000\n",
    "latent_representations = []\n",
    "for start_idx in range(0, rna_counts.shape[0], batch_size):\n",
    "    end_idx = min(start_idx + batch_size, rna_counts.shape[0])\n",
    "    with torch.no_grad():\n",
    "        latent_batch = svae.encode(rna_counts[start_idx:end_idx].to(device))\n",
    "        latent_representations.append(latent_batch.cpu())\n",
    "embed = torch.cat(latent_representations, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc_mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
